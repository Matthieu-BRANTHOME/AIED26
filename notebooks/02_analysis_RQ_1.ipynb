{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "![Logo AIED26](../assets/logo_AIED26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# **Notebook#02 : Analysis on RQ1**\n",
    "## [impact on in-game progression and learning gain]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1/ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import students_constants as stu_const\n",
    "import interaction_constants as int_const\n",
    "import tests_constants  as tes_const\n",
    "\n",
    "# External\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2/ Data importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_data = pd.read_pickle(\"../data/interim/interaction_data.pkl\")\n",
    "pre_test_data = pd.read_pickle(\"../data/interim/pre_test_data.pkl\")\n",
    "post_test_data = pd.read_pickle(\"../data/interim/post_test_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3/ In-game progression [A/B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### 3.1/ Calculate game progression (index 0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games detected: 248\n",
      "Number of progress entries computed: 248\n"
     ]
    }
   ],
   "source": [
    "# Get all STARTED actions to find maximum level reached by each student\n",
    "started_actions = interaction_data[\n",
    "    interaction_data[int_const.ACTION_DATA_KEY] == int_const.STARTED_ACTION\n",
    "]\n",
    "\n",
    "# Find maximum level reached by each student\n",
    "max_level_per_student = started_actions.groupby(\n",
    "    int_const.GAME_ID_DATA_KEY\n",
    ")[int_const.LEVEL_DATA_KEY].max()\n",
    "\n",
    "print(f\"Number of games detected: {len(max_level_per_student)}\")\n",
    "\n",
    "student_progress_data = []\n",
    "\n",
    "for game_id in max_level_per_student.index:\n",
    "    max_level = max_level_per_student[game_id]\n",
    "    \n",
    "    # Get all traces for this student at his maximum level\n",
    "    student_level_data = interaction_data[\n",
    "        (interaction_data[int_const.GAME_ID_DATA_KEY] == game_id) & \n",
    "        (interaction_data[int_const.LEVEL_DATA_KEY] == max_level)\n",
    "    ]\n",
    "    \n",
    "    # Maximum progression\n",
    "    max_progression = student_level_data[int_const.GAME_PROGRESSION_DATA_KEY].max()\n",
    "    \n",
    "    # Group id\n",
    "    group = student_level_data[int_const.GROUP_ID_DATA_KEY].iloc[0]\n",
    "\n",
    "    # Results aggregation \n",
    "    student_progress_data.append({\n",
    "        'game_id': game_id,\n",
    "        'group_id': group,\n",
    "        'max_level': max_level,\n",
    "        'max_progression': max_progression\n",
    "    })\n",
    "\n",
    "# Create progress dataframe\n",
    "progress_df = pd.DataFrame(student_progress_data)\n",
    "\n",
    "# Calculate progress index (0-100 points)\n",
    "# - Each completed level gives 12.5 points (100/8)\n",
    "# - For current level, progression percentage gives fraction of 12.5 points\n",
    "def calculate_progress_index(max_level, max_progression):\n",
    "    completed_levels_points = (max_level - 1) * (100 / 8)\n",
    "    current_level_points = (max_progression / 100) * (100 / 8)\n",
    "    return min(completed_levels_points + current_level_points, 100)\n",
    "\n",
    "progress_df['progress_index'] = progress_df.apply(\n",
    "    lambda row: calculate_progress_index(row['max_level'], row['max_progression']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Number of progress entries computed: {len(progress_df)}\")\n",
    "# Export to Excel for debug\n",
    "progress_df.to_excel(\"../debug/debug_students_game_progression.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 3.2/ Test A VS (B+C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Is there a difference in game progression between students from group A and students from group B+C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65aaede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Group A: n = 81, mean = 63.83, std = 23.74\n",
      "Group B+C: n = 167, mean = 67.41, std = 23.08\n",
      ".   Difference in mean (B+C - A): 3.58\n",
      ".   Percentage increase from Group A: 5.61%\n"
     ]
    }
   ],
   "source": [
    "# Extract progress data for each group\n",
    "group_a_progress = progress_df[progress_df['group_id'] == 'A']['progress_index']\n",
    "group_b_progress = progress_df[progress_df['group_id'] == 'B']['progress_index']\n",
    "group_c_progress = progress_df[progress_df['group_id'] == 'C']['progress_index']\n",
    "# Combine B and C into one group\n",
    "group_bc_progress = pd.concat([group_b_progress, group_c_progress])\n",
    "\n",
    "# Descriptive statistics\n",
    "average_progress_A = group_a_progress.mean()\n",
    "average_progress_BC = group_bc_progress.mean()\n",
    "\n",
    "std_progress_A = group_a_progress.std()\n",
    "std_progress_BC = group_bc_progress.std()\n",
    "\n",
    "mean_diff = average_progress_BC - average_progress_A\n",
    "percent_increase = (mean_diff / average_progress_A) * 100\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A: n = {len(group_a_progress)}, mean = {average_progress_A:.2f}, std = {std_progress_A:.2f}\")\n",
    "print(f\"Group B+C: n = {len(group_bc_progress)}, mean = {average_progress_BC:.2f}, std = {std_progress_BC:.2f}\")\n",
    "print(f\".   Difference in mean (B+C - A): {mean_diff:.2f}\")\n",
    "print(f\".   Percentage increase from Group A: {percent_increase:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 3.3/ Test A VS B VS C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Is there a difference in game progression between students from groups A, B, and C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f5b11e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Group A: n = 81, mean = 63.83, std = 23.74\n",
      "Group B: n = 94, mean = 65.88, std = 22.19\n",
      ".   diff vs A = 2.04, increase = 3.20%\n",
      "Group C: n = 73, mean = 69.40, std = 24.19\n",
      ".   diff vs A = 5.56, increase = 8.71%\n"
     ]
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "average_progress_A = group_a_progress.mean()\n",
    "average_progress_B = group_b_progress.mean()\n",
    "average_progress_C = group_c_progress.mean()\n",
    "\n",
    "diff_B = average_progress_B - average_progress_A\n",
    "percent_increase_B = (diff_B / average_progress_A) * 100\n",
    "\n",
    "diff_C = average_progress_C - average_progress_A\n",
    "percent_increase_C = (diff_C / average_progress_A) * 100\n",
    "\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A: n = {len(group_a_progress)}, mean = {average_progress_A:.2f}, std = {group_a_progress.std():.2f}\")\n",
    "print(f\"Group B: n = {len(group_b_progress)}, mean = {average_progress_B:.2f}, std = {group_b_progress.std():.2f}\")\n",
    "print(f\".   diff vs A = {diff_B:.2f}, increase = {percent_increase_B:.2f}%\")\n",
    "print(f\"Group C: n = {len(group_c_progress)}, mean = {average_progress_C:.2f}, std = {group_c_progress.std():.2f}\")\n",
    "print(f\".   diff vs A = {diff_C:.2f}, increase = {percent_increase_C:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 4/ Learning gain [A/B/C]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### 4.1/ Learning gain calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "The learning gain calculation is based on ANSWERS_SCORES dictionary (see `scr/tests_constants.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group A: 73/81 students with both pre and post tests\n",
      "Group B: 90/94 students with both pre and post tests\n",
      "Group C: 72/73 students with both pre and post tests\n"
     ]
    }
   ],
   "source": [
    "# Calculate maximum score\n",
    "max_score_general = sum(max(answer.values()) for answer in tes_const.ANSWERS_SCORES.values())\n",
    "\n",
    "# Score calculation function\n",
    "def calculate_score(student, max_score):\n",
    "    score = 0\n",
    "    for question, answer in student.items():\n",
    "        if question in tes_const.ANSWERS_SCORES and answer in tes_const.ANSWERS_SCORES[question]:\n",
    "            score += tes_const.ANSWERS_SCORES[question][answer]\n",
    "    return round((score/max_score)*100)\n",
    "\n",
    "groups = [tes_const.GROUP_A, tes_const.GROUP_B, tes_const.GROUP_C]\n",
    "scores_data = {}\n",
    "\n",
    "for group in groups:\n",
    "    # Filter and calculate scores\n",
    "    pre_temp = pre_test_data[pre_test_data[tes_const.GROUP_ID_KEY] == group].copy()\n",
    "    post_temp = post_test_data[post_test_data[tes_const.GROUP_ID_KEY] == group].copy()\n",
    "    \n",
    "    pre_temp['pre_score'] = pre_temp.apply(calculate_score, axis=1, max_score=max_score_general)\n",
    "    post_temp['post_score'] = post_temp.apply(calculate_score, axis=1, max_score=max_score_general)\n",
    "    \n",
    "    # Merge and calculate gain\n",
    "    scores_df = pd.merge(\n",
    "        pre_temp[[tes_const.STUDENT_ID_KEY, 'pre_score']],\n",
    "        post_temp[[tes_const.STUDENT_ID_KEY, 'post_score']],\n",
    "        on=tes_const.STUDENT_ID_KEY,\n",
    "        how='inner' # the student must have a pre-test score AND a post-test score\n",
    "    )\n",
    "    scores_df['learning_gain'] = scores_df['post_score'] - scores_df['pre_score']\n",
    "    \n",
    "    scores_data[group] = scores_df\n",
    "    print(f\"Group {group}: {len(scores_df)}/{sum(1 for s in stu_const.ALL_STUDENTS if s[stu_const.GROUP_ID] == group)} students with both pre and post tests\")\n",
    "    \n",
    "    # Export\n",
    "    scores_df.to_excel(f\"../debug/debug_learning_gain_{group}.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### 4.2/ Intra-group learning gain analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Do students demonstrate learning gains using Pyrates in their respective groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=======================================\n",
      "GROUP A INTRA-GROUP ANALYSIS\n",
      "========================================\n",
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Pre-test: M = 45.14, SD = 16.84\n",
      "Post-test: M = 55.26, SD = 20.65\n",
      "Learning gain: M = 10.12, SD = 18.10\n",
      "\n",
      "=== NORMALITY TESTS (Shapiro-Wilk) ===\n",
      "Shapiro-Wilk test for learning gains: p-value = 0.0457\n",
      "Learning gains are not normally distributed -> Prefer Wilcoxon test.\n",
      "\n",
      "=== TEST RESULTS ===\n",
      "Paired T-test: t = -4.7788, p-value = 0.0000\n",
      "Wilcoxon test: W = 320.0000, p-value = 0.0001\n",
      "Results (using Wilcoxon test) :\n",
      "SIGNIFICANT: p-value = 0.0001 < alpha = 0.05\n",
      "   Significant learning gain observed (+10.12 points)\n",
      "Effect Size\n",
      "r = 0.4739\n",
      "Effect size interpretation: medium\n",
      "\n",
      "=======================================\n",
      "GROUP B INTRA-GROUP ANALYSIS\n",
      "========================================\n",
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Pre-test: M = 42.89, SD = 19.79\n",
      "Post-test: M = 52.88, SD = 22.44\n",
      "Learning gain: M = 9.99, SD = 17.79\n",
      "\n",
      "=== NORMALITY TESTS (Shapiro-Wilk) ===\n",
      "Shapiro-Wilk test for learning gains: p-value = 0.0166\n",
      "Learning gains are not normally distributed -> Prefer Wilcoxon test.\n",
      "\n",
      "=== TEST RESULTS ===\n",
      "Paired T-test: t = -5.3254, p-value = 0.0000\n",
      "Wilcoxon test: W = 407.5000, p-value = 0.0000\n",
      "Results (using Wilcoxon test) :\n",
      "SIGNIFICANT: p-value = 0.0000 < alpha = 0.05\n",
      "   Significant learning gain observed (+9.99 points)\n",
      "Effect Size\n",
      "r = 0.4849\n",
      "Effect size interpretation: medium\n",
      "\n",
      "=======================================\n",
      "GROUP C INTRA-GROUP ANALYSIS\n",
      "========================================\n",
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Pre-test: M = 52.65, SD = 17.64\n",
      "Post-test: M = 60.10, SD = 19.71\n",
      "Learning gain: M = 7.44, SD = 17.06\n",
      "\n",
      "=== NORMALITY TESTS (Shapiro-Wilk) ===\n",
      "Shapiro-Wilk test for learning gains: p-value = 0.0144\n",
      "Learning gains are not normally distributed -> Prefer Wilcoxon test.\n",
      "\n",
      "=== TEST RESULTS ===\n",
      "Paired T-test: t = -3.7018, p-value = 0.0004\n",
      "Wilcoxon test: W = 362.0000, p-value = 0.0016\n",
      "Results (using Wilcoxon test) :\n",
      "SIGNIFICANT: p-value = 0.0016 < alpha = 0.05\n",
      "   Significant learning gain observed (+7.44 points)\n",
      "Effect Size\n",
      "r = 0.3721\n",
      "Effect size interpretation: medium\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "groups = [tes_const.GROUP_A, tes_const.GROUP_B, tes_const.GROUP_C]\n",
    "for group in groups:\n",
    "    scores_df = scores_data[group]\n",
    "    pre_scores = scores_df['pre_score']\n",
    "    post_scores = scores_df['post_score']\n",
    "    learning_gains = scores_df['learning_gain']\n",
    "    print(f\"\\n=======================================\")\n",
    "    print(f\"GROUP {group} INTRA-GROUP ANALYSIS\")\n",
    "    print(f\"========================================\")\n",
    "\n",
    "    print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "\n",
    "    print(f\"Pre-test: M = {pre_scores.mean():.2f}, SD = {pre_scores.std():.2f}\")\n",
    "    print(f\"Post-test: M = {post_scores.mean():.2f}, SD = {post_scores.std():.2f}\")\n",
    "    print(f\"Learning gain: M = {learning_gains.mean():.2f}, SD = {learning_gains.std():.2f}\")\n",
    "    \n",
    "    print(f\"\\n=== NORMALITY TESTS (Shapiro-Wilk) ===\")\n",
    "    # Shapiro-Wilk test for pre-post differences\n",
    "    shapiro_gain = stats.shapiro(learning_gains)\n",
    "    print(f\"Shapiro-Wilk test for learning gains: p-value = {shapiro_gain.pvalue:.4f}\")\n",
    "    \n",
    "    # Check normality\n",
    "    if shapiro_gain.pvalue >= alpha:\n",
    "        print(\"Learning gains are normally distributed -> Paired T-test is applicable.\")\n",
    "        normal_distribution = True\n",
    "    else:\n",
    "        print(\"Learning gains are not normally distributed -> Prefer Wilcoxon test.\")\n",
    "        normal_distribution = False\n",
    "    \n",
    "    print(f\"\\n=== TEST RESULTS ===\")\n",
    "    # Paired T-test\n",
    "    t_test = stats.ttest_rel(pre_scores, post_scores)\n",
    "    print(f\"Paired T-test: t = {t_test.statistic:.4f}, p-value = {t_test.pvalue:.4f}\")\n",
    "    \n",
    "    # Wilcoxon signed-rank test\n",
    "    wilcoxon_test = stats.wilcoxon(pre_scores, post_scores)\n",
    "    print(f\"Wilcoxon test: W = {wilcoxon_test.statistic:.4f}, p-value = {wilcoxon_test.pvalue:.4f}\")\n",
    "    \n",
    "    # Choose appropriate test based on normality\n",
    "    if normal_distribution:\n",
    "        recommended_pvalue = t_test.pvalue\n",
    "        test_used = \"Paired T-test\"\n",
    "    else:\n",
    "        recommended_pvalue = wilcoxon_test.pvalue\n",
    "        test_used = \"Wilcoxon test\"\n",
    "\n",
    "    # Calculate effect sizes\n",
    "    n = len(learning_gains)\n",
    "    \n",
    "    # Cohen's d for paired samples (using learning gains)\n",
    "    cohens_d = learning_gains.mean() / learning_gains.std()\n",
    "    \n",
    "    # r effect size for Wilcoxon (using z-score approximation)\n",
    "    z_wilcoxon = stats.norm.ppf(1 - wilcoxon_test.pvalue / 2)\n",
    "    r_wilcoxon = z_wilcoxon / np.sqrt(n)\n",
    "\n",
    "\n",
    "    # Choose appropriate test based on normality\n",
    "    if normal_distribution:\n",
    "        recommended_pvalue = t_test.pvalue\n",
    "        test_used = \"Paired T-test\"\n",
    "        effect_size = cohens_d\n",
    "        effect_label = \"Cohen's d\"\n",
    "        \n",
    "        # Interpret Cohen's d\n",
    "        if abs(cohens_d) < 0.2:\n",
    "            effect_interpretation = \"negligible\"\n",
    "        elif abs(cohens_d) < 0.5:\n",
    "            effect_interpretation = \"small\"\n",
    "        elif abs(cohens_d) < 0.8:\n",
    "            effect_interpretation = \"medium\"\n",
    "        else:\n",
    "            effect_interpretation = \"large\"\n",
    "    else:\n",
    "        recommended_pvalue = wilcoxon_test.pvalue\n",
    "        test_used = \"Wilcoxon test\"\n",
    "        effect_size = r_wilcoxon\n",
    "        effect_label = \"r\"\n",
    "        \n",
    "        # Interpret r\n",
    "        if abs(r_wilcoxon) < 0.1:\n",
    "            effect_interpretation = \"negligible\"\n",
    "        elif abs(r_wilcoxon) < 0.3:\n",
    "            effect_interpretation = \"small\"\n",
    "        elif abs(r_wilcoxon) < 0.5:\n",
    "            effect_interpretation = \"medium\"\n",
    "        else:\n",
    "            effect_interpretation = \"large\"\n",
    "    \n",
    "    # Interpretation\n",
    "    print(f\"Results (using {test_used}) :\")\n",
    "    \n",
    "    if recommended_pvalue < alpha:\n",
    "        print(f\"SIGNIFICANT: p-value = {recommended_pvalue:.4f} < alpha = {alpha}\")\n",
    "        if learning_gains.mean() > 0:\n",
    "            print(f\"   Significant learning gain observed (+{learning_gains.mean():.2f} points)\")\n",
    "        else:\n",
    "            print(f\"   Significant learning loss observed ({learning_gains.mean():.2f} points)\")\n",
    "    else:\n",
    "        print(f\"NOT SIGNIFICANT: p-value = {recommended_pvalue:.4f} > alpha = {alpha}\")\n",
    "        print(\"   No significant learning gain observed\")\n",
    "\n",
    "    # Display effect size\n",
    "    print(f\"Effect Size\")\n",
    "    print(f\"{effect_label} = {effect_size:.4f}\")\n",
    "    print(f\"Effect size interpretation: {effect_interpretation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### 4.3/ Inter-group learning gain comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### 4.3.1/ Test A VS (B+C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Is there a difference in learning gains between students from group A and those from group B+C ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8126867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Group A (n=73): M = 10.12, SD = 18.10\n",
      "Group B+C (n=162): M = 8.86, SD = 17.47\n",
      ".   Difference (A - B+C) = 1.27\n",
      ".   Percentage reduction compared to A = 12.50%\n"
     ]
    }
   ],
   "source": [
    "# Extract learning gains\n",
    "learning_gains_A = scores_data['A']['learning_gain']\n",
    "learning_gains_BC = pd.concat([scores_data['B']['learning_gain'], scores_data['C']['learning_gain']])\n",
    "\n",
    "# Descriptive statistics\n",
    "mean_A = learning_gains_A.mean()\n",
    "mean_BC = learning_gains_BC.mean()\n",
    "std_A = learning_gains_A.std()\n",
    "std_BC = learning_gains_BC.std()\n",
    "diff_A_BC = mean_A - mean_BC\n",
    "percent_reduction_BC = (diff_A_BC / mean_A) * 100\n",
    "\n",
    "print(\"=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A (n={len(learning_gains_A)}): M = {mean_A:.2f}, SD = {std_A:.2f}\")\n",
    "print(f\"Group B+C (n={len(learning_gains_BC)}): M = {mean_BC:.2f}, SD = {std_BC:.2f}\")\n",
    "print(f\".   Difference (A - B+C) = {diff_A_BC:.2f}\")\n",
    "print(f\".   Percentage reduction compared to A = {percent_reduction_BC:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### 4.3.2/ Test A VS B VS C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Is there a difference in learning gains between students from groups A, B, and C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9325fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "Group A (n=73): M = 10.12, SD = 18.10\n",
      "Group B (n=90): M = 9.99, SD = 17.79\n",
      ".   B vs A: Mean difference = 0.13, Percentage reduction = 1.33%\n",
      "Group C (n=72): M = 7.44, SD = 17.06\n",
      ".   C vs A: Mean difference = 2.68, Percentage reduction = 26.46%\n"
     ]
    }
   ],
   "source": [
    "# Extract learning gains for each group\n",
    "learning_gains_A = scores_data['A']['learning_gain']\n",
    "learning_gains_B = scores_data['B']['learning_gain'] \n",
    "learning_gains_C = scores_data['C']['learning_gain']\n",
    "\n",
    "# Descriptive statistics\n",
    "average_gain_A = learning_gains_A.mean()\n",
    "average_gain_B = learning_gains_B.mean()\n",
    "average_gain_C = learning_gains_C.mean()\n",
    "diff_B_vs_A = average_gain_A - average_gain_B\n",
    "diff_C_vs_A = average_gain_A - average_gain_C\n",
    "\n",
    "percent_reduction_B = (diff_B_vs_A / average_gain_A) * 100\n",
    "percent_reduction_C = (diff_C_vs_A / average_gain_A) * 100\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(f\"Group A (n={len(learning_gains_A)}): M = {average_gain_A:.2f}, SD = {learning_gains_A.std():.2f}\")\n",
    "print(f\"Group B (n={len(learning_gains_B)}): M = {average_gain_B:.2f}, SD = {learning_gains_B.std():.2f}\")\n",
    "print(f\".   B vs A: Mean difference = {diff_B_vs_A:.2f}, Percentage reduction = {percent_reduction_B:.2f}%\")\n",
    "print(f\"Group C (n={len(learning_gains_C)}): M = {average_gain_C:.2f}, SD = {learning_gains_C.std():.2f}\")\n",
    "print(f\".   C vs A: Mean difference = {diff_C_vs_A:.2f}, Percentage reduction = {percent_reduction_C:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO SL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
